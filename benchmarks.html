<!DOCTYPE html>
<html>

<head>
  <!-- Basic -->
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <!-- Mobile Metas -->
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
  <!-- Site Metas -->
  <meta name="keywords" content="" />
  <meta name="description" content="" />
  <meta name="author" content="" />

  <title>UW Dataset</title>

  <!-- slider stylesheet -->
  <!-- slider stylesheet -->
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/assets/owl.carousel.min.css" />

  <!-- bootstrap core css -->
  <link rel="stylesheet" type="text/css" href="css/bootstrap.css" />

  <!-- fonts style -->
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap" rel="stylesheet" />
  <!-- Custom styles for this template -->
  <link href="css/style.css" rel="stylesheet" />
  <!-- responsive style -->
  <link href="css/responsive.css" rel="stylesheet" />
</head>

<body>
  <div class="hero_area">
    <!-- header section strats -->
    <header class="header_section">
      <div class="container-fluid">
        <nav class="navbar navbar-expand-lg custom_nav-container ">
          <a class="navbar-brand" href="index.html">
            <span>
              UW Dataset
            </span>
          </a>
          <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
          </button>

          <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <div class="d-flex ml-auto flex-column flex-lg-row align-items-center">
              <ul class="navbar-nav  ">
                <li class="nav-item active">
                  <a class="nav-link" href="index.html">Home <span class="sr-only">(current)</span></a>
                </li>
                <li class="nav-item ">
                  <a class="nav-link" href="overview.html"> Overview </a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="benchmarks.html"> Benchmarks </a>
                </li>
                <li class="nav-item">
                  <a class="nav-link" href="#">
                    <a class="nav-link" href="download.html"> Download </a>
                  </a>
                </li>
              </ul>
              </div>
            </div>
          </div>
        </nav>
      </div>
    </header>
    <!-- end header section -->

  </div>

  <!-- about section -->

  <section class="about_section layout_padding">
    <div class="container">
      <div class="box">
        <div class="img-box">
          <img src="images/benchmark2-im.jpg" alt="">
        </div>
      </div>
      <div class="heading_container">
        <h2>
          The metrics:
        </h2>
      </div>
      <div class="box">
        <div class="detail-box">
          <p>
            <ul>
              <li>Evaluation tool: BOPtoolkit</li>
              <li>For 2D object detection: precision, recall, IoU, mAP</li>
              <li>For 6D pose estimation: ADD, ADD, COU, VSD </li>
            </ul>
          </p>
        </div>
        <div class="detail-box">
          <p>
            The first evaluation step consists of computing 2D bounding box detection metrics with the mean Average Precision (mAP) based on the Intersection over Union (IOU) scores, with a threshold of 0.5. In 6D pose estimation the most widely used metric is Average Distance to the model point (ADD) error, (eADD). If the model M has indistinguishable views, the error is calculated as the Average Distance to the Closest model point (ADI). Each estimated pose is considered correct if e < θ = k * d where k is a constant and d is the object diameter. We considered different costant k equal to 0.1, 0.2 and 0.3. In addition, we also computed Complement over Union (CoU) error recalls. This is a metric based on masks: it creates masks of the given rendered object (given the cad model and the estimated pose). Then it compares predicted and ground truth masks. CoU was computed with three threshold: 0.3, 0.5, 0.7.
      
          </p>
        
        </div>
        <div class="detail-box">
          <table>
            <tr>
              <th>CoU</th>
              <th>θ = 0.3</th>
              <th>θ = 0.5</th>
              <th>θ = 0.7</th>
            </tr>
            <tr>
              <td>Box</td>
              <td>94.6%</td>                 
              <td>100.0%</td>
              <td>100.0%</td>
            </tr>
            <tr>
              <td>Cup</td>
              <td>94.2%</td>
              <td>99.4%</td>
              <td>100.0%</td>
            </tr>
            <tr>
              <td>Jug</td>
              <td>79.6%</td>
              <td>97.8%</td>
              <td>99.6%</td>
            </tr>
            <tr>
              <td>Hotstab</td>
              <td>20.2%</td>
              <td>65.6%</td>
              <td>92.6%</td>
            </tr>
            <tr>
              <td><b>Average</b></td>
              <td>72.15%</td>
              <td>90.57%</td>
              <td>98.05%</td>
            </tr>
          </table>
        </div>

        <div class="detail-box">
          <p>
      
          </p>
        </div>
        <div class="detail-box">
          <table>
            <tr>
              <th>ADI</th>
              <th>k = 0.1</th>
              <th>k = 0.2</th>
              <th>k = 0.3</th>
            </tr>
            <tr>
              <td>Box</td>
              <td>21.6%</td>                 
              <td>51.0%</td>
              <td>60.4%</td>
            </tr>
            <tr>
              <td>Cup</td>
              <td>55.0% </td>
              <td>77.8% </td>
              <td>85.8%</td>
            </tr>
            <tr>
              <td>Jug</td>
              <td>72.2%</td>
              <td>86.6%</td>
              <td>93.0%</td>
            </tr>
            <tr>
              <td>Hotstab</td>
              <td>44.0%</td>
              <td>64.4%</td>
              <td>73.8%</td>
            </tr>
            <tr>
              <td><b>Average</b></td>
              <td>48.2%</td>
              <td>69.95% </td>
              <td>78.25%</td>
            </tr>
          </table>
        </div>
        <div class="detail-box">
          <p>
      
          </p>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="heading_container">
        <h2>
          The method comparison:
        </h2>
      </div>
      <div class="box">
        <div class="detail-box">
          <p>
            <ul>
              <li>YOLOv4 + AAE</li>
              <li>EfficientPose</li>
              <li>Yolo6D</li> 
            </ul>
          </p>
        </div>
      </div>
      <div class="box">
        <div class="detail-box">
          <p>
            Despite our dataset being mostly composed of symmetrical objects, we achieved better results when comparing with similar state-of-the-art methodologies. The following Table for the hotstab and the jug compared three different methods in terms of ADD, ADI and mAP. In particular, we chose for comparison YOLO-6D [1], which is a feature-based approach that uses Perspective’n’Point (PnP) algorithm, and EfficientPose [2], a full-frame, single-shot
method which achieves one of the higher results on LineMod Dataset. YOLO-6D and EfficientPose were trained with different input and batch sizes, different learning rates and
Adam momentum as optimizer. On the other hand, for EfficientPose the best performance is achieved with a batch size equal to 1, a learning rate of 0.0001 and 500 epochs. To ensure comparability with the other two methods, we opted for lighter versions by selecting φ equal to 0 as scaling hyperparameter. Despite the higher results on LineMod Dataset, EfficientPose achieves very low performance scores. On the other hand, YOLO-6D achieves higher performances with respect to EfficientPose, but it does not reach our pipeline percentage scores.

          </p>
        
        </div>
        <div class="detail-box">
          <table>
            <tr>
              <th>Hotstab</th>
              <th>ADD</th>
              <th>ADI</th>
              <th>mAP (θ=0.5)</th>
            </tr>
            <tr>
              <td>EfficientPose</td>
              <td>1.32%</td>                 
              <td>8.65%</td>
              <td>0.7521</td>
            </tr>
            <tr>
              <td>Yolo6D</td>
              <td>9.58% </td>
              <td>36.71% </td>
              <td>0.77</td>
            </tr>
            <tr>
              <td>YOLOv4</td>
              <td>11.4%</td>
              <td>44.0%</td>
              <td>0.99%</td>
            </tr>
          </table>
        </div>
        <div class="detail-box">
          <table>
            <tr>
              <th>Jug</th>
              <th>ADD</th>
              <th>ADI</th>
              <th>mAP (θ=0.5)</th>
            </tr>
            <tr>
              <td>EfficientPose</td>
              <td>23%</td>                 
              <td>54.8%</td>
              <td>0.7341</td>
            </tr>
            <tr>
              <td>Yolo6D</td>
              <td>26.50% </td>
              <td>58.44% </td>
              <td>0.816</td>
            </tr>
            <tr>
              <td>YOLOv4</td>
              <td>29.2%</td>
              <td>78.2%</td>
              <td>0.995%</td>
            </tr>
          </table>
        </div>
        <div class="'detail-box">
          [1] Tekin, Bugra, Sudipta N. Sinha, and Pascal Fua. "Real-time seamless single shot 6d object pose prediction." Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.
          <br>
          [2] Bukschat, Yannick, and Marcus Vetter. "EfficientPose: An efficient, accurate and scalable end-to-end 6D multi object pose estimation approach." arXiv preprint arXiv:2011.04307 (2020).
        </div>
      </div>
    </div>
  </section>
  <!-- end info_section -->

  <!-- footer section -->
  <section class="container-fluid footer_section">
    <p>
      &copy; 2023 Davide Sapienza By
      <a href="https://html.design/">Free Html Templates</a>
    </p>
  </section>
  <!-- footer section -->

  <script type="text/javascript" src="js/jquery-3.4.1.min.js"></script>
  <script type="text/javascript" src="js/bootstrap.js"></script>
  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/OwlCarousel2/2.3.4/owl.carousel.min.js">
  </script>
  <!-- owl carousel script 
    -->
  <script type="text/javascript">
    $(".owl-carousel").owlCarousel({
      loop: true,
      margin: 0,
      navText: [],
      center: true,
      autoplay: true,
      autoplayHoverPause: true,
      responsive: {
        0: {
          items: 1
        },
        1000: {
          items: 3
        }
      }
    });
  </script>
  <!-- end owl carousel script -->
</body>

</html>